{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6052052-be3a-45bf-b15d-2bea34f37a8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reg GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1159523b-027e-4460-826a-f9d4c3ec25ca",
   "metadata": {
    "id": "ifpvZjWZo3qb"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pairs_storage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#from tslearn import metrics \u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#!python -m pip install cython\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#!conda config --set channel_priority false\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#!python -m pip install https://github.com/tslearn-team/tslearn/archive/main.zip\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#conda install -c conda-forge lxm\u001b[39;00m\n\u001b[1;32m     24\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datelib_spec\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m     28\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(datelib_spec)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/cases/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding:utf-8 -*-\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcases\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcasegen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cases\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/cases/casegen.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unicode_literals\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmetacomm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinatorics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mall_pairs2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m all_pairs2 \u001b[38;5;28;01mas\u001b[39;00m allpairs\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m izip, izip_longest\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/metacomm/combinatorics/all_pairs2.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpairs_storage\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcombinatorics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xuniqueCombinations \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mitem\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pairs_storage'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "# Move to GeomPrior/aria `pip install -e ./`\n",
    "import aria \n",
    "from aria.components.dataframe_regressor import DataFrameRegressor\n",
    "from aria.components.fourier_seasonality import FourierSeasonality\n",
    "from aria.components.linear_trend import LinearTrend\n",
    "from aria.components.linear_trend_changepoints import LinearTrendChangepoints\n",
    "from aria.models.forward_stepwise_selector import ForwardStepwiseSelector\n",
    "from aria.models.linear_lasso import LinearLassoModel\n",
    "from aria.models.linear_ridge import LinearRidgeModel\n",
    "from aria.models.clustering import ists\n",
    "from aria.utils.evaluation import smape, bic, dtw_path, to_time_series\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "#from tslearn import metrics \n",
    "#!python -m pip install cython\n",
    "#!conda config --set channel_priority false\n",
    "#!python -m pip install https://github.com/tslearn-team/tslearn/archive/main.zip\n",
    "#conda install -c conda-forge lxm\n",
    "np.random.seed(0)\n",
    "\n",
    "from cases import datelib_spec\n",
    "import importlib\n",
    "importlib.reload(datelib_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9faa2a4-68a0-4f9c-95c1-162da7e266a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the reimplementation of ists algortihm and sis software\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import os\n",
    "\n",
    "class ists:\n",
    "    @staticmethod\n",
    "    def readTrainingParams():\n",
    "        #Program changes the working directory as files are opened\n",
    "        #These lines ensure the training data is located\n",
    "        previous_directory = os.getcwd()\n",
    "        #input_file_directory = os.path.dirname(os.path.realpath(sys.argv[0]))\n",
    "        #input_file_directory += \"\\\\lib\"\n",
    "        __file__ = os.getcwd()\n",
    "        root_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "        traindata_dir = 'lib'\n",
    "        input_file_directory = os.path.join(root_dir, traindata_dir)\n",
    "        os.chdir(input_file_directory)\n",
    "        input_file = \"ISTS_Training_Data_07_2013.txt\"\n",
    "        training_data = open(input_file)\n",
    "        \n",
    "        #===========================================================================\n",
    "        # Read Training Parameters\n",
    "        #===========================================================================\n",
    "        _type = np.array(training_data.readline(), np.int32)        #1\n",
    "        _key = np.array(training_data.readline(), np.int32)         #1\n",
    "        nsegments = np.array(training_data.readline(), np.int32)    #number of segments = 12\n",
    "        nstates = np.array(training_data.readline(), np.int32)      #number of states = 7\n",
    "        nclass = np.array(training_data.readline(), np.int32)       #number of classes = 25\n",
    "        source = []\n",
    "        for _i in range(nclass):\n",
    "            source = np.append(source, np.array(training_data.readline(), np.int32))\n",
    "        \n",
    "        #===========================================================================\n",
    "        # Main loop\n",
    "        # Iterated i's are [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 23]\n",
    "        #===========================================================================\n",
    "        loop = True\n",
    "        params = {}\n",
    "        while loop:\n",
    "            \n",
    "            #i = np.array(training_data.readline(), np.int32)\n",
    "            i = int(training_data.readline())\n",
    "            #print \"-\"*5,i,\"-\"*5\n",
    "            \n",
    "            p = np.matrix(np.empty((nstates,1)))\n",
    "            for j in range(nstates):\n",
    "                for k in range(1):\n",
    "                    \n",
    "                    p[j,k] =  np.array(training_data.readline(), np.float64)\n",
    "            \n",
    "            A = np.matrix(np.empty((nstates,nstates*(nsegments-1))))\n",
    "            for j in range(nstates):\n",
    "                for k in range(nstates*(nsegments-1)):\n",
    "                    A[j,k] =  np.array(training_data.readline(), np.float64)\n",
    "            \n",
    "            m = np.matrix(np.empty((3,nstates)))\n",
    "            for j in range(3):\n",
    "                for k in range(nstates):\n",
    "                    m[j,k] =  np.array(training_data.readline(), np.float64)\n",
    "            \n",
    "            V = np.matrix(np.empty((3,3*nstates)))\n",
    "            for j in range(3):\n",
    "                for k in range(3*nstates):\n",
    "                    V[j,k] =  np.array(training_data.readline(), np.float64)\n",
    "            \n",
    "            samsz = np.array(training_data.readline(), np.int32)\n",
    "        \n",
    "            lkd = np.empty(samsz)\n",
    "            for j in range(samsz):\n",
    "                lkd[j] = np.array(training_data.readline(), np.float64)\n",
    "            \n",
    "            st = np.matrix(np.empty((samsz,nsegments)))\n",
    "            for j in range(samsz):\n",
    "                for k in range(nsegments):\n",
    "                    st[j,k] =np.array(training_data.readline(), np.float32)\n",
    "            \n",
    "            pi = []\n",
    "            pi.append(i)\n",
    "            pi.append(p)\n",
    "            pi.append(A)\n",
    "            pi.append(m)\n",
    "            pi.append(V)\n",
    "            pi.append(samsz)\n",
    "            pi.append(lkd)\n",
    "            pi.append(st)\n",
    "            \n",
    "            \n",
    "            params[i] = pi\n",
    "            \n",
    "            if i == 23:\n",
    "                loop = False\n",
    "        training_data.close()\n",
    "        os.chdir(previous_directory)\n",
    "        return params, nsegments, nstates \n",
    "   \n",
    "    @staticmethod    \n",
    "    def autocorrelation(y):\n",
    "\n",
    "        lag = int(len(y)/2)\n",
    "        r_k = []\n",
    "        for i in range(1,lag+1):\n",
    "            temp = ists.covariance(y, i)\n",
    "            r_k = np.append(r_k, temp)\n",
    "        return r_k / ists.covariance(y, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def covariance(y, lag):\n",
    "        temp = 0\n",
    "        for i in range(len(y)-lag):\n",
    "            temp += (y[i]-np.mean(y)) * (y[i+lag]-np.mean(y))\n",
    "        cov = temp / (len(y)-lag)\n",
    "        return cov\n",
    "    \n",
    "    @staticmethod\n",
    "    def changesize(y, target=120):\n",
    "        x = np.arange(len(y))\n",
    "        f = interpolate.interp1d(x, y)\n",
    "        xnew = np.linspace(0, len(y)-1, target)\n",
    "        ynew = f(xnew)\n",
    "        return ynew\n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.params, self.nsegments, self.nstates = ists.readTrainingParams()\n",
    "        \n",
    "        self.IDS = [\"zero0\",\"const\",\"plinr\",\"nlinr\",\"nexgr\",\n",
    "                   \"sshgr\",\"pexgr\",\"gr1da\",\"gr1db\",\"gr2da\",\n",
    "                   \"gr2db\",\"d1peg\",\"d2peg\",\"nexdc\",\"sshdc\",\n",
    "                   \"pexdc\",\"d1gra\",\"d1grb\",\"d2gra\",\"d2grb\",\n",
    "                   \"g1ped\",\"g2ped\",\"oscct\",\"oscgr\",\"oscdc\"]\n",
    "\n",
    "        self.COLORS = [\"Gray\",\"black\",\"Teal\",\"Wheat\",\"green\",\n",
    "                     \"blue\",\"DarkBlue\",\"orange\",\"orange\",\"orange\",\n",
    "                     \"orange\",\"magenta\",\"magenta\",\"GoldenRod\",\"yellow\",\n",
    "                     \"Brown\",\"magenta\",\"magenta\",\"magenta\",\"magenta\",\n",
    "                     \"Turquoise\",\"Turquoise\",\"red\",\"Maroon\",\"IndianRed\"]\n",
    "\n",
    "        self._optimum_sequence = []\n",
    "    \n",
    "    \n",
    "    def getClassIdByName(self, name):\n",
    "        return self.IDS.index(name)\n",
    "    \n",
    "    def getClassNameById(self, id):\n",
    "        return self.IDS[id]\n",
    "        \n",
    "    def classLikelihoodAll(self, y):\n",
    "        \n",
    "        likelihood_table = []\n",
    "        \n",
    "        for beh_id in range(1,26):\n",
    " \n",
    "            likelihood_table.append(self.classLikelihood(y,beh_id))\n",
    "        \n",
    "        return likelihood_table\n",
    "        \n",
    "    def classLikelihood(self,y,beh_id):\n",
    "        #===========================================================================\n",
    "        # params[i,0]: behavior mode id \n",
    "        # params[i,1]: p\n",
    "        # params[i,2]: A\n",
    "        # params[i,3]: m\n",
    "        # params[i,4]: V\n",
    "        # params[i,5]: samsz\n",
    "        # params[i,6]: lkd\n",
    "        # params[i,7]: st\n",
    "        #===========================================================================\n",
    "        y = ists.changesize(y)\n",
    "        # List of Mirrors\n",
    "        # id:          01  02  03  04  05  06  07  08  09  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25\n",
    "        mr          = [ 0,  0,  4,  0, 14, 15, 16, 17, 18, 19, 20, 21, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0];\n",
    "        master_id   = [ 1,  2,  3,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13,  5,  6,  7,  8,  9, 10, 11, 12, 13, 23, 23, 23]\n",
    "        \n",
    "        master_beh_id = master_id[beh_id-1]\n",
    "        lhood = -10\n",
    "        \n",
    "        # z is for plain oscillation; w are slope are for de-trended oscillations\n",
    "        if beh_id == 1:\n",
    "            c = self.const(y)\n",
    "            if c ==1:\n",
    "                lhood = 10\n",
    "        elif beh_id == 2:\n",
    "            c = self.const(y)\n",
    "            if c ==2 or c==3:\n",
    "                lhood = 10\n",
    "        elif beh_id == 23:\n",
    "            z, w, slope = self.oscillationPreparation(y)\n",
    "            p = self.params[beh_id]\n",
    "            lkdin, optseq = self.viterbi(p[1], p[2], p[3], p[4], self.feat(z, self.nsegments))\n",
    "            lhood = (lkdin-np.mean(p[6])) / np.std(p[6])\n",
    "        elif beh_id == 24:\n",
    "            p = self.params[master_beh_id]\n",
    "            z, w, slope = self.oscillationPreparation(y)\n",
    "            if slope > 0.2:\n",
    "                lkdin, optseq = self.viterbi(p[1], p[2], p[3], p[4], self.feat(w, self.nsegments))\n",
    "                lhood = (lkdin-np.mean(p[6])) / np.std(p[6])  \n",
    "        elif beh_id == 25:\n",
    "            p = self.params[master_beh_id]\n",
    "            z, w, slope = self.oscillationPreparation(y)\n",
    "            if slope < 0.2:\n",
    "                lkdin, optseq = self.viterbi(p[1], p[2], p[3], p[4], self.feat(w, self.nsegments))\n",
    "                lhood = (lkdin-np.mean(p[6])) / np.std(p[6])\n",
    "            \n",
    "        elif master_beh_id == beh_id:\n",
    "            p = self.params[beh_id]\n",
    "            z = self.normalize(y)\n",
    "            lkdin, optseq = self.viterbi(p[1], p[2], p[3], p[4], self.feat(z, self.nsegments))\n",
    "            lhood = (lkdin-np.mean(p[6])) / np.std(p[6])\n",
    "        else:\n",
    "            #Mirros of master behaviors\n",
    "            p = self.params[master_beh_id]\n",
    "            z= 1.0 - self.normalize(y)\n",
    "            #print master_beh_id\n",
    "            lkdin, optseq = self.viterbi(p[1], p[2], p[3], p[4], self.feat(z, self.nsegments))\n",
    "            lhood = (lkdin-np.mean(p[6])) / np.std(p[6])\n",
    "        \n",
    "        return lhood\n",
    " \n",
    "    def feat(self, y, T):\n",
    "        \"\"\"\n",
    "        Constructs feature vector from input data y for t segments.\n",
    "        \n",
    "        First segments y into T segments, then calculates the features.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y : input row vector of size K\n",
    "        T : number of time segments (currently t=12)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        S : feature matrix of shape (3, t)\n",
    "            - 1st feature: slope of linear fit on the segment\n",
    "            - 2nd feature: curvature at the midpoint of the segment\n",
    "            - 3th feature: segment mean\n",
    "        \n",
    "        Old Reference\n",
    "        -------------\n",
    "        (Probably there are errors in writing feature 2 and 3)\n",
    "        \n",
    "         function Y=feat(X,t)\n",
    "        % FEAT(X,t) extracts features from t segments obtained from\n",
    "        % the sample vectors given as the rows of vector X.\n",
    "        % The features are based on 1st and 2nd order polynomial curve\n",
    "        % fitting on each segment.\n",
    "        % Returns matrix with columns as the observation vectors.\n",
    "        % The resulting matrix is 3 by (t * no of rows).\n",
    "        % feature 1 : slope of linear fit\n",
    "        %         2 : curvature at the beginning of the segment\n",
    "        %          3 : curvature at the middle of the segment \n",
    "        %\n",
    "        % Calls PFIT1   \n",
    "        \"\"\"\n",
    "        K = len(y)     #K=120 T=12 \n",
    "    \n",
    "        segment_length = int(round(K / T))  #segment_length=10\n",
    "\n",
    "        segments = y.reshape((T,-1))\n",
    " \n",
    "        #x = np.arange(0, segment_length)\n",
    "        \n",
    "        S = []\n",
    "        for t in range(T):\n",
    "            #print \"Current segment: \", t,\"\\nPoints: \", segments[t]\n",
    "            #feature 1: slope of linear fit\n",
    "            #slope, intercept = np.polyfit(x, segments[t], deg=1)\n",
    "            \n",
    "            _fit1, coefs = self.polyfit(segments[t], 1, K)\n",
    "            _intercept, slope = coefs\n",
    "            slope = np.float64(slope)\n",
    "            S = np.append(S, slope)\n",
    "            \n",
    "            #feature 2: curvature at the midpoint of the segment\n",
    "            #np.polyfit(deg=2) returns a,b,c as in a*x^2+b*x+c\n",
    "            #a, b, c = np.polyfit(x, segments[t], deg=2)\n",
    "            _fit2, coefs = self.polyfit(segments[t], 2, K)\n",
    "            _c, b, a = coefs\n",
    "            \n",
    "            b = np.float64(b)\n",
    "            a = np.float64(a)\n",
    "            \n",
    "            #matlab kodundaki rmid neden bu kadar farkli?\n",
    "            midpoint = 0.5 * (segment_length-1) / (K-1) #farkli ve de sacma\n",
    "            #curvature1 = (2*a) / (1 + (2*a*midpoint1 + b)**2)**(3/2)\n",
    "            #midpoint = segment_length / 2\n",
    "            \n",
    "            #This is my implementation that does not work\n",
    "            #curvature = (2*a) / np.sqrt((1 + (2*a*midpoint + b)**2))**3\n",
    "            par = b**2 + 4*a*b*midpoint + 4*(a**2)*(midpoint**2)\n",
    "            curvature = (2*a) / ((1+par)**(1.5))\n",
    "            \n",
    "            S = np.append(S, curvature)\n",
    "            \n",
    "            #feature 3: segment mean\n",
    "            segment_mean = segments[t].mean()\n",
    "            S = np.append(S, segment_mean)\n",
    "        \n",
    "        S = S.reshape((-1,3)).T\n",
    "        S = np.matrix(S)\n",
    "    \n",
    "        return S\n",
    "\n",
    "    def oscillationPreparation(self,y):\n",
    "        \"\"\"    \n",
    "        function [Y,coef2]=osprep(y)\n",
    "        % [Y,SLOPE]=osprep(y) preprocesses for oscillation\n",
    "        % calculates autocorrelation function of input y and returns the \n",
    "        % values until the first peak as the first row of Y.\n",
    "        % The second row of Y is the autocorrelation function of the detrended data.\n",
    "        % SLOPE is the slope of the trend.\n",
    "        \"\"\"    \n",
    "        MIN_SLOPE = 0.2\n",
    "        MIN_PERIOD = len(y)/1.5\n",
    "        acf = ists.autocorrelation(self.normalize(y))\n",
    "        acfpeak = self.fpeak(acf)\n",
    "        if acfpeak < MIN_PERIOD and acfpeak!= 0:\n",
    "            YN3 = self.changesize(acf[:acfpeak], len(y))\n",
    "            YN3 = self.normalize(YN3)\n",
    "        else:\n",
    "            YN3 = np.zeros(len(y))\n",
    "            \n",
    "        fit, coefs = self.polyfit(self.normalize(y), 1, len(y))\n",
    "        fit = np.array(fit)[0]\n",
    "        _intercept, slope = coefs\n",
    "        if abs(slope) > MIN_SLOPE:\n",
    "            resid = self.normalize(y)-fit\n",
    "            acf = ists.autocorrelation(self.normalize(resid))\n",
    "            if acfpeak < MIN_PERIOD and acfpeak!= 0:\n",
    "                YN4 = self.changesize(acf[:acfpeak], len(y))\n",
    "                YN4 = self.normalize(YN3)\n",
    "            else:\n",
    "                YN4 = np.zeros(len(y))\n",
    "        else:\n",
    "            YN4 = np.zeros(len(y)) \n",
    "        return YN3, YN4, slope\n",
    "    \n",
    "    def polyfit(self,x, deg, N):\n",
    "        \"\"\"\n",
    "        Fits a polynomial of order deg to the input vector.\n",
    "        \"\"\"\n",
    "        x = np.matrix(x)\n",
    "        _cx, rx =x.shape\n",
    "        #From matlab code\n",
    "        t=np.linspace(0.0, (rx-1)/(N-1), rx)\n",
    "        #My implementation does not work\n",
    "        #t=np.linspace(0.0, rx/N, rx)\n",
    "        B = np.matrix([[1.0]*rx]*(deg+1))\n",
    "        for i in range(1,deg+1):\n",
    "            B[i,:] = np.power(t,i)\n",
    "        #coef = np.linalg.inv(B*B.T)*B*x.T\n",
    "        coef = (B*B.T).I * B * x.T\n",
    "        fit = coef.T * B\n",
    "    \n",
    "        return fit, coef\n",
    "    \n",
    "    def viterbi(self, p, A, m, V, S):\n",
    "        \"\"\"\n",
    "        Implementation of Viterbi Algorithm for dynamic pattern classification.\n",
    "        Calculates the state-optimized likelihood function and the optimal\n",
    "        sequence for a non-stationary HMM model\n",
    "        \n",
    "        Input Parameters\n",
    "        ----------\n",
    "        p : initial probability column vector of shape (1, N)\n",
    "        A : state transition matrix from segment t to t+1 of shape (N, N*(T-1))\n",
    "        m : mean vector of states of shape (3, N)\n",
    "        V : covariance matrix of states of shape (3, N*3)\n",
    "        S : observation vector\n",
    "            In ISTS, S is the feature vector of shape (3, T)\n",
    "        \n",
    "        Function Parameters\n",
    "        -------------------\n",
    "        N : number ot states (in current version N=7)\n",
    "        T : number of time segments (in current version T=12)\n",
    "        B : Set of posteriori density of observation vectors in states\n",
    "            of shape (N, T)\n",
    "            b_j(o_t) : observation vector o_t in state j.\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        lkd : state-optimized likelihood function\n",
    "        optseq : optimum state sequence\n",
    "        \n",
    "        Old Reference\n",
    "        -------------\n",
    "        function [lkd,optseq]=viterbi(p,A,m,V,S)\n",
    "        % [lkd,optseq]=viterbi(p,A,m,V,S) calculates the state-optimized \n",
    "        %       likelihood function and the optimal state sequence for a\n",
    "        %    nonstationary HMM model.\n",
    "        %    INPUTS :\n",
    "        %        p : the initial probability vector (column)\n",
    "        %    A : [A1 A2 ... A(t-1)] (n*t n), \n",
    "        %        Ai as the state transition matrix from segment i to i+1\n",
    "        %     m : [m1 m2 .. mn], mi is the mean vector of state i\n",
    "        %    V : [V1 V2 .. Vn], Vi as the covariance matrix of the vectors for state i\n",
    "        %    S : matrix of input sequence of observation vectors (column)\n",
    "        %    OUTPUTS :\n",
    "        %    lkd : state optimized likelihood function\n",
    "        %    optseq : optimal state sequence, [q1 q2 ... qt] \n",
    "        %    where,\n",
    "        %    n=number of states,\n",
    "        %    t=number of segments.\n",
    "        \n",
    "        Techical Note:\n",
    "            (a * b) gives matrix multiply both for np.matrices and in Matlab(R)\n",
    "            Inside this function all of the parameters are used as np.matrices. Ok!\n",
    "            Otherwise (a * b) would give element-wise multiplication for np.arrays.\n",
    "        \"\"\"\n",
    "        N, _nt1 = A.shape\n",
    "        rS, T = S.shape\n",
    "        \n",
    "        #===========================================================================\n",
    "        # Density Function Values\n",
    "        # Calculate B matrix\n",
    "        #===========================================================================    \n",
    "        B = []\n",
    "        for i in range(N):\n",
    "            C = V[:, i*rS:(i+1)*rS]\n",
    "            constant = 1 / ( ((2*np.pi)**rS) * np.sqrt(np.linalg.det(C)) )\n",
    "            for t in range(T):\n",
    "                omm = S[:, t] - m[:, i]\n",
    "                b_it = constant * np.exp(-0.5 * omm.T * np.linalg.inv(C) * omm)\n",
    "                B = np.append(B, b_it)\n",
    "        B = np.reshape(B,(N,T))\n",
    "        B = np.matrix(B)\n",
    "        \n",
    "        \n",
    "        #===========================================================================\n",
    "        # Logarithmic Conversions \n",
    "        #===========================================================================\n",
    "        logp = self.logl(np.copy(p))\n",
    "        logA = self.logl(np.copy(A))\n",
    "        logB = self.logl(np.copy(B))\n",
    "        #Technical note: I had to us np.copy(x) otherwise it changes the original\n",
    "        \n",
    "        #===========================================================================\n",
    "        # Viterbi Algorithm Step 1: Initialization\n",
    "        #===========================================================================\n",
    "        #This is the first time we use this initialization method\n",
    "        d = np.matrix([[0.0]*N]*T)\n",
    "        psi = np.matrix([[0.0]*N]*T)\n",
    "        # i.e. t=0\n",
    "        d[0] = logp.T + logB[:,0].T\n",
    "    \n",
    "        #===========================================================================\n",
    "        # Viterbi Algorithm Step 2: Recursive Computation\n",
    "        #===========================================================================\n",
    "        for t in range(1,T):\n",
    "            for j in range(0,N):\n",
    "                dd = d[t-1] + (logA[:,j+(t-1)*N]).T + logB[j, t]\n",
    "                d[t, j] = np.max(dd)\n",
    "                psi[t, j] = np.argmax(dd)\n",
    "    \n",
    "        #===========================================================================\n",
    "        # Viterbi Algorithm Step 3: Termination\n",
    "        #===========================================================================\n",
    "        lkd = np.max(d[T-1])\n",
    "        optseq = np.array([0]*T)\n",
    "        optseq[T-1] = np.argmax(d[T-1])\n",
    "        for t in range(T-2, -1, -1):\n",
    "            optseq[t] = psi[t+1, optseq[t+1]]\n",
    "    \n",
    "        return lkd, optseq\n",
    "    \n",
    "    \n",
    "    def const(self,y):\n",
    "        band = 0.05\n",
    "        mean = np.mean(y)\n",
    "        maxgap = np.max(y) - np.min(y)\n",
    "        if mean==0 and maxgap==0:\n",
    "            return 1    #constant with zero mean\n",
    "        if mean!=0 and maxgap==0:\n",
    "            return 2    #constant with non-zero mean\n",
    "        q1 = y <= mean*(1+band)\n",
    "        q2 = y >= mean*(1-band)\n",
    "        inband = np.all(q1*q2)\n",
    "        if maxgap!=0 and inband:\n",
    "            return 3    #constant within band\n",
    "        else:\n",
    "            return 0    #not constant\n",
    "    \n",
    "\n",
    "\n",
    "    def fpeak(self,x):\n",
    "        \"\"\"fpeak(y) finds the first peak in the signal y\"\"\"\n",
    "        #Get difference between 2 succeeding elements of an array\n",
    "        diff = x[1:] - x[:-1]\n",
    "        #Get Signum function values -1, 0, 1\n",
    "        d = np.sign(diff)\n",
    "        \n",
    "        pos = 0\n",
    "        #p = len(d)+1\n",
    "        p = 0\n",
    "        i = 1\n",
    "        peak_found = 0\n",
    "        \n",
    "        while peak_found == 0 and i<=len(d):\n",
    "            if pos == 1 and d[i-1] <= 0:\n",
    "                p = i\n",
    "                peak_found = 1\n",
    "            if d[i-1] > 0:\n",
    "                pos = 1\n",
    "            i = i + 1\n",
    "        return p\n",
    "    \n",
    "    def logl(self,x):\n",
    "        rX, cX = x.shape\n",
    "        for i in range(rX):\n",
    "            for j in range(cX):\n",
    "                x[i,j] = np.log(max(1.0e-10, x[i,j]))\n",
    "        return x\n",
    "        \n",
    "    def normalize(self, y):\n",
    "        y = (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "        return y\n",
    "\n",
    "    def smooth(self, a, alpha):\n",
    "        '''\n",
    "        Exponential smoothing\n",
    "        '''\n",
    "        s = np.copy(a)\n",
    "        s[0] = a[0]\n",
    "        for i in range(1, len(a)-1):\n",
    "            s[i] = alpha * a[i] + (1 - alpha) * s[i-1]\n",
    "        return s\n",
    "\n",
    "    def testDataClass(self, y, hypothesisCode):\n",
    "        \n",
    "        hypothesisResult = False\n",
    "        table = self.classLikelihoodAll(y, self.params, self.nsegments)\n",
    "        \n",
    "        \n",
    "        weak = 0\n",
    "        if np.max(table) <= -2:\n",
    "            weak = 1\n",
    "            \n",
    "        if self.IDS[np.argmax(table)] == hypothesisCode:\n",
    "            hypothesisResult = True\n",
    "        \n",
    "        return hypothesisResult, table, weak\n",
    "\n",
    "\n",
    "########## ToDo: Check single hypothesis without going through the loop  \n",
    "#     def CheckHypothesis(self, y, hypothesisCode):\n",
    "#         value = self.classLikelihood(y, self.params, self.nseg, self.IDS.index(behavior))\n",
    "#         weak = 0\n",
    "#         \n",
    "#         if value > -2:\n",
    "#             return True,weak\n",
    "#         else:\n",
    "#             return False,weak\n",
    "    def getClassId(self,y):    \n",
    "        table = self.classLikelihoodAll(y)\n",
    "        return np.argmax(table)\n",
    "    def getClassName(self,y):\n",
    "        table = self.classLikelihoodAll(y)\n",
    "        return self.getClassNameById(np.argmax(table))\n",
    "    def getPeriod(self, x):\n",
    "        s = self.smooth(x, 0.5)\n",
    "        acf = ists.autocorrelation(s)\n",
    "        period = self.fpeak(acf)\n",
    "        if period == len(x)/2:\n",
    "            period = 0\n",
    "        return period\n",
    "\n",
    "    \n",
    "# -> classLikelihoodAll(y) \n",
    "# -> getClassId(y) returns the id of the class that given data is belong to after behavior classification ex. class_id = ists_instance.getClassId(y)\n",
    "\n",
    "# -> getPeriod(y) returns the period of the given data. ex. period = ists_instance.getPeriod(y)\n",
    "\n",
    "# -> smooth(y) applies exponential smoothing to the given data and returns the smoothed data. ex. smoothed_y = ists_instance.smooth(y)\n",
    "\n",
    "# -> normalize(y) normalizes the given data and returns the normalized data ex. normalized_y = ists_instance.normalize(y)\n",
    "\n",
    "# -> getClassIdByName(name) returns the id of the class used in the classification ex. class_id = ists_instance.GetClassIdByName('gr1da')\n",
    "\n",
    "# -> getClassNameById(id) returns the name of the class used in the classification ex. class_name = ists_instance.GetClassNameById(2)\n",
    "\n",
    "# **Functions that can be used without creating an instance\n",
    "\n",
    "# -> autocorrelation(y) returns the autocorrelation of the data\n",
    "# ex. autocor_y = ists.autocorrelation(y) -> covariance(y) returns the covariance of the data ex. cov_y = ists.covariance(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609048e-8fb1-40df-91fc-bdb037d07871",
   "metadata": {},
   "source": [
    "returns likelihood table containing scores of all possible classes. ex. table = ists_instance.classLikelihoodAll(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ab469db-5cf9-4c1e-b4f6-45b0010fd4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-10,\n",
       " -10,\n",
       " -6.714078211577249,\n",
       " -11.90813047827989,\n",
       " -10.895207136226709,\n",
       " -15.760666662720517,\n",
       " -10.17023996848618,\n",
       " -14.488833732672056,\n",
       " -15.579306430083168,\n",
       " -10.45755372937909,\n",
       " -10.79227033193496,\n",
       " -9.938492408933012,\n",
       " -9.003563063788647,\n",
       " -12.610065610041337,\n",
       " -26.850412717334034,\n",
       " -18.319155955179504,\n",
       " -10.959306129493218,\n",
       " -14.231153479228665,\n",
       " -11.391689594546865,\n",
       " -9.703496439254218,\n",
       " -13.106045803081932,\n",
       " -10.600857076084893,\n",
       " -6.928992856647389,\n",
       " -6.928992856647389,\n",
       " -10]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import os\n",
    "\n",
    "y = sp500.loc[:, 'Adj Close']\n",
    "\n",
    "bats = ists()\n",
    "bats.classLikelihoodAll(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7263b3b1-85f6-4d1c-9182-7f75f78f37e5",
   "metadata": {},
   "source": [
    "returns the id of the class that given data is belong to after behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8495dfcf-ac35-4d8b-a317-66664db5fd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bats.getClassId(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda841d0-bb54-4c90-84cd-880863b9caf0",
   "metadata": {},
   "source": [
    "returns the period of the given data. ex. period = ists_instance.getPeriod(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f56eca3-9a41-4467-8e91-6aed7ed4958e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bats.getPeriod(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0285c94d-fda9-432d-81d4-1d6f35dc4020",
   "metadata": {
    "id": "r3htnJqfhy4G"
   },
   "outputs": [],
   "source": [
    "def download_prices_from_yf(ticker, start_date, end_date, label_list):\n",
    "    yf.pdr_override()\n",
    "    start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    return pdr.get_data_yahoo(ticker, start_date, end_date)[label_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feffb4f-5246-4f02-8b58-b7781cec3ecd",
   "metadata": {},
   "source": [
    "## Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89f4cea-b459-41cb-bc51-eff3f6ec4c6e",
   "metadata": {
    "id": "Wet7q8VxmHUj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "sp500 = download_prices_from_yf(start_date='2009-05-01', end_date='2021-01-01',\n",
    "              ticker='^GSPC', label_list=['Adj Close'])\n",
    "real_close = sp500['Adj Close']\n",
    "real_return = np.log(real_close).diff().dropna()\n",
    "real_mean = real_return.mean()\n",
    "real_std = real_return.std()\n",
    "standard_return = (real_return-real_mean)/real_std\n",
    "sequence_data = np.asarray(standard_return) \n",
    "\n",
    "scaled_sp500_diff = sp500.rename(columns = {\"Date\":\"ds\", \"Adj Close\": \"y\"}).iloc[1:, :]\n",
    "scaled_sp500_diff.reset_index(inplace = True)\n",
    "scaled_sp500_diff.rename(columns = {\"Date\":\"ds\", \"y\":\"y\"}, inplace = True)\n",
    "scaled_sp500_diff['y'] = sequence_data\n",
    "df = scaled_sp500_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8677d-60cc-4704-bfc3-5fcea988aa7f",
   "metadata": {},
   "source": [
    "## TS decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e53812-6839-4013-99ce-7155fac95c1e",
   "metadata": {
    "id": "RzG7cHtgo3qc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE\n",
      "SMAPE 1.7181945029369528\n",
      "Lasso\n",
      "SMAPE 2.0\n",
      "w.o.trendchangpoint\n",
      "SMAPE 1.7246242378411143\n"
     ]
    }
   ],
   "source": [
    "n = int(df.shape[0] * 0.8)\n",
    "train_df, test_df = df.iloc[:n], df.iloc[n:]\n",
    "\n",
    "components = [\n",
    "    LinearTrend(),\n",
    "    LinearTrendChangepoints(),\n",
    "    FourierSeasonality(7, 3),\n",
    "    FourierSeasonality(30.4375, 5),\n",
    "    FourierSeasonality(365.25, 10),\n",
    "]\n",
    "\n",
    "components2 = [\n",
    "    LinearTrend(),\n",
    "    FourierSeasonality(7, 3),\n",
    "    FourierSeasonality(30.4375, 5),\n",
    "    FourierSeasonality(365.25, 10),\n",
    "]\n",
    "print('RIDGE') \n",
    "m = LinearRidgeModel(components=components) \n",
    "m.fit(train_df)\n",
    "#print(pd.DataFrame(index=m1.get_features_list(), data=m1.get_params()))\n",
    "print('SMAPE', smape(test_df['y'], m.predict(test_df)['yhat']))\n",
    "\n",
    "print('Lasso') \n",
    "m1 = LinearLassoModel(components=components)\n",
    "m1.fit(train_df)\n",
    "#print(pd.DataFrame(index=m2.get_features_list(), data=m2.get_params()))\n",
    "print('SMAPE', smape(test_df['y'], m1.predict(test_df)['yhat']))\n",
    "\n",
    "print('w.o.trendchangpoint') \n",
    "m2 = LinearRidgeModel(components=components2)\n",
    "m2.fit(train_df)\n",
    "#print(pd.DataFrame(index=m2.get_features_list(), data=m2.get_params()))\n",
    "print('SMAPE', smape(test_df['y'], m2.predict(test_df)['yhat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb56c84-1a1f-433d-88f3-04819c39455b",
   "metadata": {
    "id": "eIxGtn2yo3qc"
   },
   "source": [
    "- Ridge (normal prior) has a lower SMAPE (1.71 vs 1.77) than Lasso.\n",
    "- With changepoints has a lower SMAPE (1.718 vs 1.724) than without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a5bd20-007d-435e-a30e-c1a343259050",
   "metadata": {
    "id": "zDERsSiHo3qc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'coef'}>]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_coef = pd.DataFrame({\"feature\": m.get_features_list(), \"coef\": m.get_params()})\n",
    "season_coef = m_coef[m_coef.feature.str.contains('FS')]\n",
    "season_coef.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e45ffb-fe89-44c4-a980-5171c9066a3f",
   "metadata": {},
   "source": [
    "## Will be doing (after 08/19): TS clustering\n",
    "- start from compute_mask import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa63b7de-f3c9-44f1-953c-8b962d3533cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_x = np.array(\n",
    "    [-0.790, -0.765, -0.734, -0.700, -0.668, -0.639, -0.612, -0.587, -0.564,\n",
    "     -0.544, -0.529, -0.518, -0.509, -0.502, -0.494, -0.488, -0.482, -0.475,\n",
    "     -0.472, -0.470, -0.465, -0.464, -0.461, -0.458, -0.459, -0.460, -0.459,\n",
    "     -0.458, -0.448, -0.431, -0.408, -0.375, -0.333, -0.277, -0.196, -0.090,\n",
    "     0.047, 0.220, 0.426, 0.671, 0.962, 1.300, 1.683, 2.096, 2.510, 2.895,\n",
    "     3.219, 3.463, 3.621, 3.700, 3.713, 3.677, 3.606, 3.510, 3.400, 3.280,\n",
    "     3.158, 3.038, 2.919, 2.801, 2.676, 2.538, 2.382, 2.206, 2.016, 1.821,\n",
    "     1.627, 1.439, 1.260, 1.085, 0.917, 0.758, 0.608, 0.476, 0.361, 0.259,\n",
    "     0.173, 0.096, 0.027, -0.032, -0.087, -0.137, -0.179, -0.221, -0.260,\n",
    "     -0.293, -0.328, -0.359, -0.385, -0.413, -0.437, -0.458, -0.480, -0.498,\n",
    "     -0.512, -0.526, -0.536, -0.544, -0.552, -0.556, -0.561, -0.565, -0.568,\n",
    "     -0.570, -0.570, -0.566, -0.560, -0.549, -0.532, -0.510, -0.480, -0.443,\n",
    "     -0.402, -0.357, -0.308, -0.256, -0.200, -0.139, -0.073, -0.003, 0.066,\n",
    "     0.131, 0.186, 0.229, 0.259, 0.276, 0.280, 0.272, 0.256, 0.234, 0.209,\n",
    "     0.186, 0.162, 0.139, 0.112, 0.081, 0.046, 0.008, -0.032, -0.071, -0.110,\n",
    "     -0.147, -0.180, -0.210, -0.235, -0.256, -0.275, -0.292, -0.307, -0.320,\n",
    "     -0.332, -0.344, -0.355, -0.363, -0.367, -0.364, -0.351, -0.330, -0.299,\n",
    "     -0.260, -0.217, -0.172, -0.128, -0.091, -0.060, -0.036, -0.022, -0.016,\n",
    "     -0.020, -0.037, -0.065, -0.104, -0.151, -0.201, -0.253, -0.302, -0.347,\n",
    "     -0.388, -0.426, -0.460, -0.491, -0.517, -0.539, -0.558, -0.575, -0.588,\n",
    "     -0.600, -0.606, -0.607, -0.604, -0.598, -0.589, -0.577, -0.558, -0.531,\n",
    "     -0.496, -0.454, -0.410, -0.364, -0.318, -0.276, -0.237, -0.203, -0.176,\n",
    "     -0.157, -0.145, -0.142, -0.145, -0.154, -0.168, -0.185, -0.206, -0.230,\n",
    "     -0.256, -0.286, -0.318, -0.351, -0.383, -0.414, -0.442, -0.467, -0.489,\n",
    "     -0.508, -0.523, -0.535, -0.544, -0.552, -0.557, -0.560, -0.560, -0.557,\n",
    "     -0.551, -0.542, -0.531, -0.519, -0.507, -0.494, -0.484, -0.476, -0.469,\n",
    "     -0.463, -0.456, -0.449, -0.442, -0.435, -0.431, -0.429, -0.430, -0.435,\n",
    "     -0.442, -0.452, -0.465, -0.479, -0.493, -0.506, -0.517, -0.526, -0.535,\n",
    "     -0.548, -0.567, -0.592, -0.622, -0.655, -0.690, -0.728, -0.764, -0.795,\n",
    "     -0.815, -0.823, -0.821])\n",
    "\n",
    "s_y1 = np.concatenate((s_x, s_x)).reshape((-1, 1))\n",
    "s_y2 = np.concatenate((s_x, s_x[::-1])).reshape((-1, 1))\n",
    "sz = s_y1.shape[0]\n",
    "\n",
    "path, sim = dtw_path(s_y1, s_y2)\n",
    "\n",
    "plt.figure(1, figsize=(8, 8))\n",
    "\n",
    "# definitions for the axes\n",
    "left, bottom = 0.01, 0.1\n",
    "w_ts = h_ts = 0.2\n",
    "left_h = left + w_ts + 0.02\n",
    "width = height = 0.65\n",
    "bottom_h = bottom + height + 0.02\n",
    "\n",
    "rect_s_y = [left, bottom, w_ts, height]\n",
    "rect_gram = [left_h, bottom, width, height]\n",
    "rect_s_x = [left_h, bottom_h, width, h_ts]\n",
    "\n",
    "ax_gram = plt.axes(rect_gram)\n",
    "ax_s_x = plt.axes(rect_s_x)\n",
    "ax_s_y = plt.axes(rect_s_y)\n",
    "\n",
    "mat = cdist(s_y1, s_y2)\n",
    "\n",
    "ax_gram.imshow(mat, origin='lower')\n",
    "ax_gram.axis(\"off\")\n",
    "ax_gram.autoscale(False)\n",
    "ax_gram.plot([j for (i, j) in path], [i for (i, j) in path], \"w-\",\n",
    "             linewidth=3.)\n",
    "\n",
    "ax_s_x.plot(numpy.arange(sz), s_y2, \"b-\", linewidth=3.)\n",
    "ax_s_x.axis(\"off\")\n",
    "ax_s_x.set_xlim((0, sz - 1))\n",
    "\n",
    "ax_s_y.plot(- s_y1, numpy.arange(sz), \"b-\", linewidth=3.)\n",
    "ax_s_y.axis(\"off\")\n",
    "ax_s_y.set_ylim((0, sz - 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d485be0-19c6-4dc3-bfe7-6a6723de749c",
   "metadata": {
    "id": "3t5ibNo05jCB"
   },
   "outputs": [],
   "source": [
    "def train_step_raw(images, generator, discriminator, generator_optimizer, discriminator_optimizer, choice, pre_trained=None):\n",
    "    noise = tf.random.normal((images.shape[0],) + generator.input_shape[1:])\n",
    "\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      if choice == 'wgan_gp':\n",
    "        disc_loss = discriminator_loss(real_output, fake_output, choice, generated_images = generated_images, images= images, discriminator=discriminator)\n",
    "      else:\n",
    "        disc_loss = discriminator_loss(real_output, fake_output, choice)\n",
    "\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)   \n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    noise = tf.random.normal((images.shape[0],) + generator.input_shape[1:])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output, choice)\n",
    "\n",
    "      if pre_trained is not None: \n",
    "        pre_trained_output = pre_trained(generated_images, training=True) # 0 or 1 from D2\n",
    "        gen_loss += generator_loss(pre_trained_output, choice)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)     \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c25ce-481f-4603-95f4-5d59312a3617",
   "metadata": {
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "def train(dataset, batchsize, generator, discriminator, G_opt, D_opt, test, epochs, choice, pre_trained=None):\n",
    "  train_step = tf.function(train_step_raw)\n",
    "  dataset = dataset.astype('float32')\n",
    "  image_batch = tf.Variable(initial_value=np.zeros((batchsize,)+dataset.shape[1:]), trainable=False, dtype='float32')\n",
    "  datasize = dataset.shape[0]\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    G_list = []; D_list = []\n",
    "\n",
    "    for i in range(datasize//batchsize):\n",
    "      image_batch.assign(dataset[np.random.choice(datasize, size=batchsize, replace=False)])\n",
    "      gen_loss, disc_loss = train_step(image_batch, generator, discriminator, G_opt, D_opt, choice, pre_trained)\n",
    "      G_list.append(gen_loss)\n",
    "      D_list.append(disc_loss) \n",
    "\n",
    "    G_loss.append(np.mean(G_list))\n",
    "    D_loss.append(np.mean(D_list))\n",
    "\n",
    "    for fun, seed in test:\n",
    "      fun(generator, epoch + 1, seed) \n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea1fca1-1007-4952-9c84-a0ca8f0c585b",
   "metadata": {
    "id": "WOQugGsshKG0"
   },
   "source": [
    "## Quant GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e699ecf-5c9f-4c7b-8485-c1e1077cc3b7",
   "metadata": {
    "id": "agB6IdCmWbkF"
   },
   "outputs": [],
   "source": [
    "# official\n",
    "\n",
    "prelu_kwargs = {'alpha_initializer':tf.keras.initializers.Constant(value=0.25), 'shared_axes':[1,2]}\n",
    "\n",
    "def TemporalBlock(x, skip, output_dim, hidden_dim_skip, kernel_size, dilation, num_inner_blocks=2, batch_norm=False, **kwargs):\n",
    "    drop_left = num_inner_blocks * (kernel_size - 1) * dilation\n",
    "    in_dim = x.shape[-1]\n",
    "\n",
    "    x_0 = x\n",
    "\n",
    "    for i in range(num_inner_blocks):\n",
    "      init = tf.keras.initializers.RandomUniform(minval=-1/np.sqrt(x.shape[2]*kernel_size), maxval=1/np.sqrt(x.shape[2]*kernel_size))\n",
    "      inits = {'kernel_initializer': init, 'bias_initializer': init}\n",
    "      x = tfa.layers.SpectralNormalization(layers.Conv1D(output_dim, kernel_size, strides=1, \n",
    "                                                       padding='valid', dilation_rate=dilation, **inits, **kwargs))(x)\n",
    "      x = layers.PReLU(**prelu_kwargs)(x) \n",
    "      if batch_norm:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    if in_dim != output_dim: \n",
    "      init = tf.keras.initializers.RandomUniform(minval=-1/np.sqrt(x_0.shape[2]*1), maxval=1/np.sqrt(x_0.shape[2]*1))\n",
    "      inits = {'kernel_initializer': init, 'bias_initializer': init}\n",
    "      x_0 = tfa.layers.SpectralNormalization(layers.Conv1D(output_dim, 1, strides=1, padding='same', **inits, **kwargs))(x_0) \n",
    "    \n",
    "    x = x + x_0[:,drop_left:]\n",
    "    init = tf.keras.initializers.RandomUniform(minval=-1/np.sqrt(x.shape[2]*1), maxval=1/np.sqrt(x.shape[2]*1))\n",
    "    inits = {'kernel_initializer': init, 'bias_initializer': init}\n",
    "    skip = skip + tfa.layers.SpectralNormalization(layers.Conv1D(hidden_dim_skip, 1, strides=1, padding='same', **inits, **kwargs))(x[:, -skip.shape[1]:])\n",
    "    \n",
    "    return layers.PReLU(**prelu_kwargs)(x), skip\n",
    "\n",
    "def TCN(x, output_dim, hidden_dims, hidden_dim_skip=50, \n",
    "        kernel_size=2, num_inner_blocks=2, dilation_factor=2, batch_norm=False, **kwargs):\n",
    "    drop_left =  sum(num_inner_blocks * (kernel_size - 1) * dilation_factor**min(i,6) for i in range(len(hidden_dims)))\n",
    "    skip = tf.zeros([tf.shape(x)[0], x.shape[1] - drop_left, hidden_dim_skip])\n",
    "    \n",
    "    x, skip = TemporalBlock(x, skip, hidden_dims[0], hidden_dim_skip, 1, 1, num_inner_blocks=2, batch_norm=batch_norm, **kwargs)\n",
    "    for i, h in enumerate(hidden_dims):\n",
    "        x, skip = TemporalBlock(x, skip, h, hidden_dim_skip, kernel_size, dilation_factor**min(i,6), num_inner_blocks=2, batch_norm=batch_norm, **kwargs)\n",
    "    \n",
    "    y = layers.PReLU(**prelu_kwargs)(skip) \n",
    "    init = tf.keras.initializers.RandomUniform(minval=-1/np.sqrt(y.shape[2]*1), maxval=1/np.sqrt(y.shape[2]*1))\n",
    "    inits = {'kernel_initializer': init, 'bias_initializer': init}\n",
    "    y = tfa.layers.SpectralNormalization(layers.Conv1D(hidden_dim_skip, 1, strides=1, padding='same', **inits, **kwargs))(y) \n",
    "    y = layers.PReLU(**prelu_kwargs)(y) \n",
    "    y = tfa.layers.SpectralNormalization(layers.Conv1D(output_dim, 1, strides=1, padding='same', **inits, **kwargs))(y) \n",
    "    return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
