{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from cmdstanpy import CmdStanModel\n",
    "from stanify.calibrator.draws_data_mapper import draws2data2draws\n",
    "from stanify.calibrator.calib_utilities import check_consistency\n",
    "import random\n",
    "random.seed(10)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  developing model families using visual diagnostics and numeric summaries\n",
    "If you run the user interface code which states input and output format as below, it creates specific model, data, plot (two `.stan`, two `.nc files, multiple plots) in three folders. With minimal number of clicks, your model quality can be inspected. This aim of this vignette is to inspect how given the two outputs (model and data) can be analyzed for your next move.\n",
    "\n",
    "keyword: simulation-based calibration, pair plots, divergence, InferenceData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div>\n",
    "<img src=\"../vensim_models/inventory/inven_1est_invenadjtime.png\" width=\"800\"/>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## user interface"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precision ={\n",
    "    \"S\": 100, # # of draws from prior\n",
    "    \"M\": 200, # # of draws from posterior (# of chains * # of draws from each chain)\n",
    "    \"N\": 10, # # of observation\n",
    "    \"R\": 2, # # of subgroups for hierarchical Bayes\n",
    "}\n",
    "\n",
    "setting = {\n",
    "    \"est_param_names\" : [\"inventory_adjustment_time\", \"wip_adjustment_time\"],\n",
    "    \"hier_est_param_names\": [\"inventory_adjustment_time\"],\n",
    "    \"target_simulated_vector_names\" : [\"production_rate_stocked\", \"production_start_rate_stocked\"],\n",
    "    \"driving_vector_names\" : [\"customer_order_rate\"],\n",
    "    \"model_name\": \"Inven\"\n",
    "}\n",
    "init_order = 100\n",
    "# driving data\n",
    "numeric = {\n",
    "        \"customer_order_rate\": np.sin(np.arange(0, precision['N'])*1000) * init_order * .5 + init_order\n",
    "}\n",
    "\n",
    "prior = {\n",
    "    (\"inventory_adjustment_time\", \"normal\", 8.0, 0.8, 0),\n",
    "    (\"wip_adjustment_time\", \"normal\", 2, 0.02, 0),\n",
    "    (\"m_noise_scale\", \"normal\", init_order * .1, init_order * .01, 0)\n",
    "}\n",
    "\n",
    "output_format = dict(\n",
    "    prior_predictive=[\"production_rate_stocked_obs\", \"production_start_rate_stocked_obs\"],\n",
    "    posterior_predictive=[\"production_rate_stocked_obs_post\", \"production_start_rate_stocked_obs_post\"],\n",
    "    log_likelihood={\n",
    "        \"loglik\": \"loglik\"\n",
    "    },\n",
    "    coords={\n",
    "        \"time\": [n for n in range(precision['N'])],\n",
    "        \"stock\": setting['target_simulated_vector_names'],\n",
    "        \"region\": [r for r in range(precision['R'])]\n",
    "    },\n",
    "    dims={\n",
    "        'initial_outcome': [\"stock\"],\n",
    "        'integrated_result': [\"time\", \"stock\"],\n",
    "        'production_rate_stocked': [\"time\"],\n",
    "        'production_start_rate_stocked': [\"time\"],\n",
    "        'process_noise': [\"time\"],\n",
    "        \"production_rate_stocked_obs\": [\"time\"],\n",
    "        \"production_start_rate_stocked_obs\": [\"time\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "if check_consistency(setting, precision, numeric, prior, output_format):\n",
    "    idata_orig, model = draws2data2draws('../vensim_models/inventory/inventory_wopnoise.mdl', setting, precision, numeric, prior, output_format)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We load produced data for plotting. Please refer to the end of this document for model (stan code) and data structure which is Stanify's main contribution, but not the scope here.\n",
    "\n",
    "`data2draws` have four groups: `posterior`, `prior_predictive`, `log_likelihood`, `samp_stats`, `observed_data`. First click the arrow below to inspect dataset structure of each group. If you click database icon, it will show each data variable (estimated parameter, target simulated vectors for `posterior` group, observed vector (adding measurement noise on target simulated vector posterior) for `osberved_data` group, loglikelihood of each posterior sample for `log_likelihood`, lp, acceptance_rate, tree_depth, energy (HMC alg.parameters) `sample_stats_prior` group)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sbc = az.from_netcdf(f\"data/{model.model_name}/sbc_2est_mnoise0.nc\")\n",
    "sbc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sbc.observed_data.to_dataframe().plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Posterior is very tight without much uncertainty"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.plot_posterior(sbc, var_names=setting['est_param_names'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The [forest plot](https://arviz-devs.github.io/arviz/api/generated/arviz.plot_forest.html) shows chains are stuck. Generally, each chain has different values, so plot_posterior that combines gives a semblance of kde, but for this model, each chain returns always the same exact value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "summary function returns mean, sd, credible interval for estimated parameter and target simulated vector. mcse, effective sample size (ess), r_hat tells quality of each variables' sample. Refer to [Stan manual](https://mc-stan.org/docs/reference-manual/effective-sample-size.html) for ess details. From large number of r_hat, the covergence of four chains are not good which is verified in more detail below. 1.2 is the usual threshold for r_hat."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.summary(sbc.posterior[setting['est_param_names']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.summary(sbc.posterior['m_noise_scale'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The PPC (prior/poseterior predictive check) plot is a standard way for Bayesian checking. It serves complementary role with simulation-based calibration (SBC). Two checks happen in different space: PPC in observation space as time series, SBC in parameter space as rank comparison between the ground truth and retrieved estimated samples. From the plot, posterior predictive's negative values is the most problematic which was expected as the currrent version uses normal likelihood. Changing this to lognoraml or negative binomial can solve this problem, but lognormal has thicker tail creating difficult posterior geometry and negative binomial need transformation to integer value which is known to be not accurate."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "new plot that compares against time is needed for dynamic models. posterior predictive is quite different from general bayse models."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_pairs = dict()\n",
    "for obs_name in output_format['prior_predictive']:\n",
    "    data_pairs[obs_name] = f'{obs_name}_post'\n",
    "az.plot_ppc(sbc, data_pairs = data_pairs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# loglikliehood plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Appendix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(CmdStanModel(stan_file=f\"stan_files/{model.model_name}/draws2data.stan\").code())\n",
    "print(CmdStanModel(stan_file=f\"stan_files/{model.model_name}/data2draws.stan\").code())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}