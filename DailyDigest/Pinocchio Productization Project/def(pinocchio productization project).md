Pinocchio principle: a model created for computational purposes has a life on its own. 
Pinocchio productization: Reverse-engineer the model using an automated testing framework. This automation leads to the productization of good-quality models, giving us more opportunities to finish with the best-quality models.

## abstract
New techniques introduce new challenges. Hierarchical modeling is attractive in the context of spatial and temporal compartment disaggregation, but its challenge in statistical computation hinders the wide use of this technique. To make hierarchical dynamic modeling easy and affordable, we analyze what complicates this concept and why its computation is costly. Then,  we introduce three tools (prior modeling, model checking, and re-parameterization) that can prevent modelers from these hindrances. Three template dynamic models from the system dynamics domain (two stock negative loop oscillators (prey-predator), growth generated by contacts between two groups (SIR, SEIR), and stock management structure (inventory) models are used for illustration.

## intro
We merge branched approaches sequentially. From dynamic modeling, we discuss agent-based and compartment modeling, and from statistical modeling, we discuss bayesian and frequentist approaches. Merging branched concepts is essential for mapping concepts. As our target audience is any modeler with dynamic modeling or statistics experience, using a representative language so that each reader can the concept back to their domain is important. 

Based on this table, we illustrate an actionable workflow on which stakeholders’ demand, expert's structural knowledge, and machine learning algorithms are balanced and tested. Our focus is on automating this flow as much as possible with modular design to supply an explainable policy. Some may argue against automation, as the process of chiseling the model ensures its quality. However, we are not proposing a full-automation. Automating the testing framework leads to the productization of good-quality models, giving us more opportunity to finish with the best-quality models.

  

Table1: Statistics (Bayes-Freq) - Dynamic model (compartment - agent)

-   [Typify parameters to assumed or assumed time-series or estimated for testing](https://github.com/Data4DM/BayesSD/discussions/7)


## related work

  

Method focused: stat.testing summarized in [Modrak22](https://drive.google.com/file/d/1-lw9rgyjCEiaBP6SLevP9TeWzV5lpQQd/view?usp=share_link), in SD? other than Barlas96

Domain focused:

-   epidemiology: [Avoidable errors in modeling](https://royalsocietypublishing.org/doi/10.1098/rspb.2015.0347) and others
```
-   the validity of the statistical estimation procedure hinges on the independence of sequential measurement errors, which is clearly violated when observations are accumulated through time”
-   models should be fit to raw, disaggregated data whenever possible and never to temporally accumulated data;
-   when model assumptions, such as independence of errors, must be violated, careful checks for the effects of such violations should be performed;
-   forecasts based on deterministic models, being by nature incapable of accurately communicating uncertainty, should be avoided
-   stochastic models should be preferred to deterministic models in most circumstances because they afford improved accounting for real variability and increased opportunity for quantifying uncertainty. Post hoc comparison of simulated and actual data is a powerful and general procedure that can be used to distinguish model misspecification from real stochasticity.   
```
-   ecology: Tom’s deer chronic disease 
    



- [[def(branched)]]
- [[def(merging branched)]]
- 

### 3.2. statistical analysis

Rashomon effect is a situation in which an event is given contradictory interpretations and used to describe the phenomenon of the unreliability of eyewitnesses. The following figure from Efron’s Statistical computer age, illustrates vertical and horizontal conditioning of Bayesian and Frequentist inference in a higher dimension. Due to our cognitive limitation, Bayesian and Frequentists have seemingly different approaches. However, they are different projections of the same joint data and parameters. Having a point mass prior, Frequentist approach is one of Bayesian approaches. Bayesian can also be Frequentist by corresponding Bayesian prior distribution to the frequentist sample space from https://statmodeling.stat.columbia.edu/2018/06/17/bayesians-are-frequentists/ and Christian added (as comment) how frequentist's loss function correspond to Bayesian's prior and how both aim for decision sets of minimal average size with the only difference being the dimension along which error is controlled.



  
  

### 3.3. dynamic-statistical simulation analysis

description of input and output implemented in stanify

  

Variable type definition: 

-   Syntax for input and output
    

![](https://lh3.googleusercontent.com/-4n0zG-B1qW3Hu9vKjLagaiFVzjUH0xi3mwRHDsy-hDlXl62b7qG2ONhz9JMAwmicPQ7SqoO_KuTuIlxCcE22HVzKonqMLND1JnO-vBuTdoiqdZTUcWTo2h2UxOPBVni-z4QgQYQr1m8CI4CsrBr40FT35zwX_KuCm3PsoGpIRl3Ss_TV-vF-grwf50AGQ)

input

```

precision ={

    "S": 1, # # of draws from prior

    "M": 100, # # of draws from posterior (# of chains * # of draws from each chain)

    "N": 40, # # of observation

    "R": 3, # # of subgroups for hierarchical Bayes

}

  

setting = {

    "est_param_names": ["prey_birth_frac", "pred_birth_frac"],

    "hier_est_param_names" : ["pred_birth_frac"],

    "target_simulated_vector_names": ["prey", "predator"],

    "driving_vector_names": ["process_noise_uniform_driving"],

}

  

numeric = {

    "process_noise_uniform_driving": np.random.uniform(low=-.5, high=.5, size = precision['N']),

    'process_noise_scale': 0.01

}

  

prior = {

    ("prey_birth_frac", "normal", 0.8, 0.08, 0),

    ("pred_birth_frac", "normal", 0.05, 0.005, 0),

    ("m_noise_scale", "normal", 1, .1, 0)

}

  

```

output

  

![](https://lh3.googleusercontent.com/NjQP6UzAMlkeIN9XAelJQh1aUu4j-aQ4UwKhbaaaFnBZFBsBJTOlGo3CuV6bWGZ8HLla9m5JNn4RqhIpF0S5qtLVhamAIvmuLMTVikK6iBTPDqKRySUOeLVtGBQ1gFk1o95E5EyBaA_kTDSG7OCC4BeA74mLScud8LIrFBv2JGpyrcCRuSwKpxg2QabAPg)

  
  

### 3.4. branching optimization algorithms

-   short comparison of bootstrap, filtering, HMC, pMCMC. Para18 compared four optimizers Genetic Algorithms, Simulated Annealing, Powell’s Algorithm, and a hybrid algorithm but we focus on algorithms that can represent posterior and posterior predictive uncertainty
    
-   [likelihood free estimation, msm, test quantities driven MCMC](https://github.com/Data4DM/BayesSD/discussions/110)
    

![](https://lh4.googleusercontent.com/KBOLHaaYslhaYEa0WN1riLkPeLbs-sywY-Y5UEUE3YFaeS5fCcekYkYZnzuBylqSAJbPFoUNUX-LFzDZLgAetgQb297NgH-hV-ofQm5MGJlJ_CLL45S-grB7t7KWkQYYXQMMMho2nuMbvGIW8nksItOds8hBgnLB1Zteg2eUak9NhwsiAy42LKLzF2imeA)

  

## 4. Joker completes Batman

We introduce three cities where joker completes batman, other than Gotham city. 

#### City1: overparameterization

##### Joker: degeneracy

definition of degeneracy and identifiability in dynamic models

1.  additive: measurements are informed by only the sum of two parameters 
    

-   posterior shape: line 
    
-   suppression strategies: tight prior, scaling strategies, compares the weakly informative prior model to the reparameterization and removal
    
-   e.g. two compartments and their adjustment time  
      
    

2.  multiplication: 
    

-   posterior shape: xy = c 
    
-   suppression strategies
    

-   e.g. market size * market share  
     
    

3.  discrete allocation: exchangeable mixture model
    

-   posterior shape: multimodal  
    Multimodality as a heterogenous combination of homogenous units VS a homogenous combination of heterogeneous units 
    
-   suppression strategies: embed prior known order, [convexification](https://github.com/Data4DM/BayesSD/discussions/116)
    
-   e.g. allocation, leader and follower’s market share
    

![](https://lh5.googleusercontent.com/z14SwgF-Y6hsMjMkeU9FXGIfiftSpgwYGFndYCAIiXte5MDUpBs-vvRn4rqBb9aeMO-1MBYYjxPcfm67RSwBpcHltRbRVkyFdHMaQyk_YRa1cdv7AFGs-o7yHD8sn67NQ_hgsMpw35jLHrZen9F4Q2O8ZgMLu4biA50_mK6-hztCJUPo2BIjeAszrwKCpg)

additive and multiplicative (green: divergence) and the effect of increasing N

##### Batman: order

  

#### City2: estimating noise

#### Joker2: near zero scale parameter

-   #### [top ten trolls](https://github.com/Data4DM/BayesSD/discussions/121)
    

  

##### Joker: multimodality

-     
    

##### Batman: order

: embedding order prior knowledge in parameter space

  

#### City3: hierarchical model 

##### Joker: 

-   ##### funnel: this is different from degeneracy as this is optimization algorithm-specific unlike degeneracy. Gibbs sampler and HMC for centered parameterized hierarchical model from funnel whereas non-centered parameterization doesn’t.
    
-   #### near zero scale parameter:
    

##### Batman: order

-   sbc
    
-   divergence diagnostic: Jair’s SEIR example (problem only occurs below .5), 
    

## 5. Geppetto chisels Pinocchio

Overlooked importance of S, M, N, P, Q, and time step

-   [how to make assumption iceberg visible](https://github.com/Data4DM/BayesSD/discussions/43)
    

  
  

## 6. Hierarchical draws2data causes data2draw uncertainty 

#### Recovery quality under uncertainty

parameter retrieval quality (RQ) is a measure of model trustability defined as

##### syntax: 

-   numerically as sbc distance from uniformity metric, predictive quantities
    
-    visually as no divergence, pair plot simulate the model with some samples from the posterior and compare them against the data. This gives me a visual check of a "good fit".Pair Plot to evaluate the shape of the joint posterior distribution. Add correlations for more information. Lots of correlations indicate a difficult parameter space. Trace plots. For marginal distributions, I found it useful to overlap prior & posterior histograms. This plot tells how much information we gained from the inference process for a particular parameter.
    

##### semantic:

-   [Effect of process noise and hierarchy measured by parameter retrieval quality (RQ)](https://github.com/Data4DM/BayesSD/discussions/118)
    

  
  

#### Draws2data, data2draws uncertainty and noise

-   process and measurement noise during draws2data and data2draws
    

![](https://lh5.googleusercontent.com/igNWrpYtlFJWw1goCpC4oCvTm5wNTq8WeXTjnpT_zaNDhxOsOBlnBdjoerQvagE7i-B4G9rzjp5Mfk7TkfqPOKv-s4-uXVhyDGutntp8XPj-ibVpRTYghDujZaN8_aGD8d_LlHEqvaI2-2rdeeRab5AUl5TVX9PV38OnXgv_mFs0s4sANSGDLfu8wChNAw)

  

soft and hard constraint

-   how to decide giving prior or range
    
-   how user-defined constraints are encoded under the hood 
    

-   given the first two moments (mean and sd) PERT prior
    
-   given only the first moment (mean) -> normal( mean, .1 of mean)
    

  

#### Role of hierarchy 

-   experiment tool for heterogeneity (homogeneous treatment of heterogeneous unit VS heterogeneous treatment of homogeneous unit)
    
-   a.k.a process noise
    

  
  
**